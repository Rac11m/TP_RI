{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DropZone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"Index/DescripteursSplitLancaster.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/DescripteursSplitPorter.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/DescripteursTokenLancaster.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/DescripteursTokenPorter.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/InverseSplitLancaster.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/InverseSplitPorter.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/InverseTokenLancaster.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "with open(file=\"Index/InverseTokenPorter.txt\", mode='w') as f :\n",
    "    f.write('')\n",
    "\n",
    "# with open(file='./*.txt', mode='r') as f:\n",
    "#     txt = f.read()\n",
    "# print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D1': 'Query Reformulation(QR) is a set of techniques used to transform a user’s original search query to a text that better aligns with the user’s intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better reformulations with relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over the previous zero-shot state-of-art. On the MSMarco Passage Ranking task, GenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback, and 9% nDCG@10 using relevant feedback documents.', 'D2': 'Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these challenging ranking formulations. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL 2019 and 2020, PRP based on the Flan-UL2 model with 20B parameters performs favorably with the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that has 50x (estimated) model size, while outperforming other LLM-based solutions, such as InstructGPT which has 175B parameters, by over 10% for all ranking metrics. By using the same prompt template on seven BEIR tasks, PRP outperforms supervised baselines and outperforms the blackbox commercial ChatGPT solution by 4.2% and pointwise LLM-based solutions by more than 10% on average NDCG@10. Furthermore, we propose several variants of PRP to improve efficiency and show that it is possible to achieve competitive results even with linear complexity', 'D3': 'Large language models (LLM) have manifested unparalleled modeling capability on various tasks, e.g., multi-step reasoning, but the input to these models is mostly limited to plain text, which could be very long and contain noisy information. Long text could take long time to process, and thus may not be efficient enough for recommender systems that require immediate response. In LLM-based recommendation models, user and item IDs are usually filled in a template (i.e., discrete prompt) to allow the models to understand a given task, but the models usually need extensive fine-tuning to bridge the user/item IDs and the template words and to unleash the power of LLM for recommendation. To address the problems, we propose to distill the discrete prompt for a specific task to a set of continuous prompt vectors so as to bridge IDs and words and to reduce the inference time. We also design a training strategy with an attempt to improve the efficiency of training these models. Experimental results on three real-world datasets demonstrate the effectiveness of our PrOmpt Distillation (POD) approach on both sequential recommendation and top-N recommendation tasks. Although the training efficiency can be significantly improved, the improvement of inference efficiency is limited. This finding may inspire researchers in the community to further improve the inference efficiency of LLM-based recommendation models.', 'D4': \"Query reformulation is a well-known problem in Information Retrieval (IR) aimed at enhancing single search successful completion rate by automatically modifying user's input query. Recent methods leverage Large Language Models (LLMs) to improve query reformulation, but often generate limited and redundant expansions, potentially constraining their effectiveness in capturing diverse intents. In this paper, we propose GenCRF: a Generative Clustering and Reformulation Framework to capture diverse intentions adaptively based on multiple differentiated, well-generated queries in the retrieval phase for the first time. GenCRF leverages LLMs to generate variable queries from the initial query using customized prompts, then clusters them into groups to distinctly represent diverse intents. Furthermore, the framework explores to combine diverse intents query with innovative weighted aggregation strategies to optimize retrieval performance and crucially integrates a novel Query Evaluation Rewarding Model (QERM) to refine the process through feedback loops. Empirical experiments on the BEIR benchmark demonstrate that GenCRF achieves state-of-the-art performance, surpassing previous query reformulation SOTAs by up to 12% on nDCG@10. These techniques can be adapted to various LLMs, significantly boosting retriever performance and advancing the field of Information Retrieval.\", 'D5': \"Session search involves a series of interactive queries and actions to fulfill user's complex information need. Current strategies typically prioritize sequential modeling for deep semantic understanding, overlooking the graph structure in interactions. While some approaches focus on capturing structural information, they use a generalized representation for documents, neglecting the word-level semantic modeling. In this paper, we propose Symbolic Graph Ranker (SGR), which aims to take advantage of both text-based and graph-based approaches by leveraging the power of recent Large Language Models (LLMs). Concretely, we first introduce a set of symbolic grammar rules to convert session graph into text. This allows integrating session history, interaction process, and task instruction seamlessly as inputs for the LLM. Moreover, given the natural discrepancy between LLMs pre-trained on textual corpora, and the symbolic language we produce using our graph-to-text grammar, our objective is to enhance LLMs' ability to capture graph structures within a textual format. To achieve this, we introduce a set of self-supervised symbolic learning tasks including link prediction, node content generation, and generative contrastive learning, to enable LLMs to capture the topological information from coarse-grained to fine-grained. Experiment results and comprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm the superiority of our approach. Our paradigm also offers a novel and effective methodology that bridges the gap between traditional search strategies and modern LLMs.\", 'D6': 'The description of an item plays a pivotal role in providing concise and informative summaries to captivate potential viewers and is essential for recommendation systems. Traditionally, such descriptions were obtained through manual web scraping techniques, which are time-consuming and susceptible to data inconsistencies. In recent years, Large Language Models (LLMs), such as GPT-3.5, and open source LLMs like Alpaca have emerged as powerful tools for natural language processing tasks. In this paper, we have explored how we can use LLMs to generate detailed descriptions of the items. To conduct the study, we have used the MovieLens 1M dataset comprising movie titles and the Goodreads Dataset consisting of names of books and subsequently, an open-sourced LLM, Alpaca, was prompted with few-shot prompting on this dataset to generate detailed movie descriptions considering multiple features like the names of the cast and directors for the ML dataset and the names of the author and publisher for the Goodreads dataset. The generated description was then compared with the scraped descriptions using a combination of Top Hits, MRR, and NDCG as evaluation metrics. The results demonstrated that LLM-based movie description generation exhibits significant promise, with results comparable to the ones obtained by web-scraped descriptions.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '../Collection/'\n",
    "\n",
    "# print(os.path.exists(path))\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file=file_path, mode='r') as f:\n",
    "        # print(f.read())\n",
    "        return f.read()\n",
    "    \n",
    "txt_contents = {}\n",
    "\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.txt'):\n",
    "        file_path = f'{path}/{file}'\n",
    "\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "        txt_contents[file_name] = read_txt_file(file_path)\n",
    "\n",
    "print(txt_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=f'Collection/D1.txt', mode='r') as f:\n",
    "    txt1 = f.read()\n",
    "with open(file=f'Collection/D2.txt', mode='r') as f:\n",
    "    txt2 = f.read()\n",
    "with open(file=f'Collection/D3.txt', mode='r') as f:\n",
    "    txt3 = f.read()\n",
    "with open(file=f'Collection/D4.txt', mode='r') as f:\n",
    "    txt4 = f.read()\n",
    "with open(file=f'Collection/D5.txt', mode='r') as f:\n",
    "    txt5 = f.read()\n",
    "with open(file=f'Collection/D6.txt', mode='r') as f:\n",
    "    txt6 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer\n",
    "\n",
    "Porter = PorterStemmer()\n",
    "Lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D1': ['query', 'reformulation(qr)', 'is', 'a', 'set', 'of', 'techniques', 'used', 'to', 'transform', 'a', 'user’s', 'original', 'search', 'query', 'to', 'a', 'text', 'that', 'better', 'aligns', 'with', 'the', 'user’s', 'intent', 'and', 'improves', 'their', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'has', 'been', 'shown', 'to', 'be', 'a', 'promising', 'approach', 'due', 'to', 'its', 'ability', 'to', 'exploit', 'knowledge', 'inherent', 'in', 'large', 'language', 'models.', 'by', 'taking', 'inspiration', 'from', 'the', 'success', 'of', 'ensemble', 'prompting', 'strategies', 'which', 'have', 'benefited', 'many', 'tasks,', 'we', 'investigate', 'if', 'they', 'can', 'help', 'improve', 'query', 'reformulation.', 'in', 'this', 'context,', 'we', 'propose', 'an', 'ensemble', 'based', 'prompting', 'technique,', 'genqrensemble', 'which', 'leverages', 'paraphrases', 'of', 'a', 'zero-shot', 'instruction', 'to', 'generate', 'multiple', 'sets', 'of', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance.', 'we', 'further', 'introduce', 'its', 'post-retrieval', 'variant,', 'genqrensemblerf', 'to', 'incorporate', 'pseudo', 'relevant', 'feedback.', 'on', 'evaluations', 'over', 'four', 'ir', 'benchmarks,', 'we', 'find', 'that', 'genqrensemble', 'generates', 'better', 'reformulations', 'with', 'relative', 'ndcg@10', 'improvements', 'up', 'to', '18%', 'and', 'map', 'improvements', 'upto', '24%', 'over', 'the', 'previous', 'zero-shot', 'state-of-art.', 'on', 'the', 'msmarco', 'passage', 'ranking', 'task,', 'genqrensemblerf', 'shows', 'relative', 'gains', 'of', '5%', 'mrr', 'using', 'pseudo-relevance', 'feedback,', 'and', '9%', 'ndcg@10', 'using', 'relevant', 'feedback', 'documents.'], 'D2': ['ranking', 'documents', 'using', 'large', 'language', 'models', '(llms)', 'by', 'directly', 'feeding', 'the', 'query', 'and', 'candidate', 'documents', 'into', 'the', 'prompt', 'is', 'an', 'interesting', 'and', 'practical', 'problem.', 'however,', 'researchers', 'have', 'found', 'it', 'difficult', 'to', 'outperform', 'fine-tuned', 'baseline', 'rankers', 'on', 'benchmark', 'datasets.', 'we', 'analyze', 'pointwise', 'and', 'listwise', 'ranking', 'prompts', 'used', 'by', 'existing', 'methods', 'and', 'argue', 'that', 'off-the-shelf', 'llms', 'do', 'not', 'fully', 'understand', 'these', 'challenging', 'ranking', 'formulations.', 'in', 'this', 'paper,', 'we', 'propose', 'to', 'significantly', 'reduce', 'the', 'burden', 'on', 'llms', 'by', 'using', 'a', 'new', 'technique', 'called', 'pairwise', 'ranking', 'prompting', '(prp).', 'our', 'results', 'are', 'the', 'first', 'in', 'the', 'literature', 'to', 'achieve', 'state-of-the-art', 'ranking', 'performance', 'on', 'standard', 'benchmarks', 'using', 'moderate-sized', 'open-sourced', 'llms.', 'on', 'trec-dl', '2019', 'and', '2020,', 'prp', 'based', 'on', 'the', 'flan-ul2', 'model', 'with', '20b', 'parameters', 'performs', 'favorably', 'with', 'the', 'previous', 'best', 'approach', 'in', 'the', 'literature,', 'which', 'is', 'based', 'on', 'the', 'blackbox', 'commercial', 'gpt-4', 'that', 'has', '50x', '(estimated)', 'model', 'size,', 'while', 'outperforming', 'other', 'llm-based', 'solutions,', 'such', 'as', 'instructgpt', 'which', 'has', '175b', 'parameters,', 'by', 'over', '10%', 'for', 'all', 'ranking', 'metrics.', 'by', 'using', 'the', 'same', 'prompt', 'template', 'on', 'seven', 'beir', 'tasks,', 'prp', 'outperforms', 'supervised', 'baselines', 'and', 'outperforms', 'the', 'blackbox', 'commercial', 'chatgpt', 'solution', 'by', '4.2%', 'and', 'pointwise', 'llm-based', 'solutions', 'by', 'more', 'than', '10%', 'on', 'average', 'ndcg@10.', 'furthermore,', 'we', 'propose', 'several', 'variants', 'of', 'prp', 'to', 'improve', 'efficiency', 'and', 'show', 'that', 'it', 'is', 'possible', 'to', 'achieve', 'competitive', 'results', 'even', 'with', 'linear', 'complexity'], 'D3': ['large', 'language', 'models', '(llm)', 'have', 'manifested', 'unparalleled', 'modeling', 'capability', 'on', 'various', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'but', 'the', 'input', 'to', 'these', 'models', 'is', 'mostly', 'limited', 'to', 'plain', 'text,', 'which', 'could', 'be', 'very', 'long', 'and', 'contain', 'noisy', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'to', 'process,', 'and', 'thus', 'may', 'not', 'be', 'efficient', 'enough', 'for', 'recommender', 'systems', 'that', 'require', 'immediate', 'response.', 'in', 'llm-based', 'recommendation', 'models,', 'user', 'and', 'item', 'ids', 'are', 'usually', 'filled', 'in', 'a', 'template', '(i.e.,', 'discrete', 'prompt)', 'to', 'allow', 'the', 'models', 'to', 'understand', 'a', 'given', 'task,', 'but', 'the', 'models', 'usually', 'need', 'extensive', 'fine-tuning', 'to', 'bridge', 'the', 'user/item', 'ids', 'and', 'the', 'template', 'words', 'and', 'to', 'unleash', 'the', 'power', 'of', 'llm', 'for', 'recommendation.', 'to', 'address', 'the', 'problems,', 'we', 'propose', 'to', 'distill', 'the', 'discrete', 'prompt', 'for', 'a', 'specific', 'task', 'to', 'a', 'set', 'of', 'continuous', 'prompt', 'vectors', 'so', 'as', 'to', 'bridge', 'ids', 'and', 'words', 'and', 'to', 'reduce', 'the', 'inference', 'time.', 'we', 'also', 'design', 'a', 'training', 'strategy', 'with', 'an', 'attempt', 'to', 'improve', 'the', 'efficiency', 'of', 'training', 'these', 'models.', 'experimental', 'results', 'on', 'three', 'real-world', 'datasets', 'demonstrate', 'the', 'effectiveness', 'of', 'our', 'prompt', 'distillation', '(pod)', 'approach', 'on', 'both', 'sequential', 'recommendation', 'and', 'top-n', 'recommendation', 'tasks.', 'although', 'the', 'training', 'efficiency', 'can', 'be', 'significantly', 'improved,', 'the', 'improvement', 'of', 'inference', 'efficiency', 'is', 'limited.', 'this', 'finding', 'may', 'inspire', 'researchers', 'in', 'the', 'community', 'to', 'further', 'improve', 'the', 'inference', 'efficiency', 'of', 'llm-based', 'recommendation', 'models.'], 'D4': ['query', 'reformulation', 'is', 'a', 'well-known', 'problem', 'in', 'information', 'retrieval', '(ir)', 'aimed', 'at', 'enhancing', 'single', 'search', 'successful', 'completion', 'rate', 'by', 'automatically', 'modifying', \"user's\", 'input', 'query.', 'recent', 'methods', 'leverage', 'large', 'language', 'models', '(llms)', 'to', 'improve', 'query', 'reformulation,', 'but', 'often', 'generate', 'limited', 'and', 'redundant', 'expansions,', 'potentially', 'constraining', 'their', 'effectiveness', 'in', 'capturing', 'diverse', 'intents.', 'in', 'this', 'paper,', 'we', 'propose', 'gencrf:', 'a', 'generative', 'clustering', 'and', 'reformulation', 'framework', 'to', 'capture', 'diverse', 'intentions', 'adaptively', 'based', 'on', 'multiple', 'differentiated,', 'well-generated', 'queries', 'in', 'the', 'retrieval', 'phase', 'for', 'the', 'first', 'time.', 'gencrf', 'leverages', 'llms', 'to', 'generate', 'variable', 'queries', 'from', 'the', 'initial', 'query', 'using', 'customized', 'prompts,', 'then', 'clusters', 'them', 'into', 'groups', 'to', 'distinctly', 'represent', 'diverse', 'intents.', 'furthermore,', 'the', 'framework', 'explores', 'to', 'combine', 'diverse', 'intents', 'query', 'with', 'innovative', 'weighted', 'aggregation', 'strategies', 'to', 'optimize', 'retrieval', 'performance', 'and', 'crucially', 'integrates', 'a', 'novel', 'query', 'evaluation', 'rewarding', 'model', '(qerm)', 'to', 'refine', 'the', 'process', 'through', 'feedback', 'loops.', 'empirical', 'experiments', 'on', 'the', 'beir', 'benchmark', 'demonstrate', 'that', 'gencrf', 'achieves', 'state-of-the-art', 'performance,', 'surpassing', 'previous', 'query', 'reformulation', 'sotas', 'by', 'up', 'to', '12%', 'on', 'ndcg@10.', 'these', 'techniques', 'can', 'be', 'adapted', 'to', 'various', 'llms,', 'significantly', 'boosting', 'retriever', 'performance', 'and', 'advancing', 'the', 'field', 'of', 'information', 'retrieval.'], 'D5': ['session', 'search', 'involves', 'a', 'series', 'of', 'interactive', 'queries', 'and', 'actions', 'to', 'fulfill', \"user's\", 'complex', 'information', 'need.', 'current', 'strategies', 'typically', 'prioritize', 'sequential', 'modeling', 'for', 'deep', 'semantic', 'understanding,', 'overlooking', 'the', 'graph', 'structure', 'in', 'interactions.', 'while', 'some', 'approaches', 'focus', 'on', 'capturing', 'structural', 'information,', 'they', 'use', 'a', 'generalized', 'representation', 'for', 'documents,', 'neglecting', 'the', 'word-level', 'semantic', 'modeling.', 'in', 'this', 'paper,', 'we', 'propose', 'symbolic', 'graph', 'ranker', '(sgr),', 'which', 'aims', 'to', 'take', 'advantage', 'of', 'both', 'text-based', 'and', 'graph-based', 'approaches', 'by', 'leveraging', 'the', 'power', 'of', 'recent', 'large', 'language', 'models', '(llms).', 'concretely,', 'we', 'first', 'introduce', 'a', 'set', 'of', 'symbolic', 'grammar', 'rules', 'to', 'convert', 'session', 'graph', 'into', 'text.', 'this', 'allows', 'integrating', 'session', 'history,', 'interaction', 'process,', 'and', 'task', 'instruction', 'seamlessly', 'as', 'inputs', 'for', 'the', 'llm.', 'moreover,', 'given', 'the', 'natural', 'discrepancy', 'between', 'llms', 'pre-trained', 'on', 'textual', 'corpora,', 'and', 'the', 'symbolic', 'language', 'we', 'produce', 'using', 'our', 'graph-to-text', 'grammar,', 'our', 'objective', 'is', 'to', 'enhance', \"llms'\", 'ability', 'to', 'capture', 'graph', 'structures', 'within', 'a', 'textual', 'format.', 'to', 'achieve', 'this,', 'we', 'introduce', 'a', 'set', 'of', 'self-supervised', 'symbolic', 'learning', 'tasks', 'including', 'link', 'prediction,', 'node', 'content', 'generation,', 'and', 'generative', 'contrastive', 'learning,', 'to', 'enable', 'llms', 'to', 'capture', 'the', 'topological', 'information', 'from', 'coarse-grained', 'to', 'fine-grained.', 'experiment', 'results', 'and', 'comprehensive', 'analysis', 'on', 'two', 'benchmark', 'datasets,', 'aol', 'and', 'tiangong-st,', 'confirm', 'the', 'superiority', 'of', 'our', 'approach.', 'our', 'paradigm', 'also', 'offers', 'a', 'novel', 'and', 'effective', 'methodology', 'that', 'bridges', 'the', 'gap', 'between', 'traditional', 'search', 'strategies', 'and', 'modern', 'llms.'], 'D6': ['the', 'description', 'of', 'an', 'item', 'plays', 'a', 'pivotal', 'role', 'in', 'providing', 'concise', 'and', 'informative', 'summaries', 'to', 'captivate', 'potential', 'viewers', 'and', 'is', 'essential', 'for', 'recommendation', 'systems.', 'traditionally,', 'such', 'descriptions', 'were', 'obtained', 'through', 'manual', 'web', 'scraping', 'techniques,', 'which', 'are', 'time-consuming', 'and', 'susceptible', 'to', 'data', 'inconsistencies.', 'in', 'recent', 'years,', 'large', 'language', 'models', '(llms),', 'such', 'as', 'gpt-3.5,', 'and', 'open', 'source', 'llms', 'like', 'alpaca', 'have', 'emerged', 'as', 'powerful', 'tools', 'for', 'natural', 'language', 'processing', 'tasks.', 'in', 'this', 'paper,', 'we', 'have', 'explored', 'how', 'we', 'can', 'use', 'llms', 'to', 'generate', 'detailed', 'descriptions', 'of', 'the', 'items.', 'to', 'conduct', 'the', 'study,', 'we', 'have', 'used', 'the', 'movielens', '1m', 'dataset', 'comprising', 'movie', 'titles', 'and', 'the', 'goodreads', 'dataset', 'consisting', 'of', 'names', 'of', 'books', 'and', 'subsequently,', 'an', 'open-sourced', 'llm,', 'alpaca,', 'was', 'prompted', 'with', 'few-shot', 'prompting', 'on', 'this', 'dataset', 'to', 'generate', 'detailed', 'movie', 'descriptions', 'considering', 'multiple', 'features', 'like', 'the', 'names', 'of', 'the', 'cast', 'and', 'directors', 'for', 'the', 'ml', 'dataset', 'and', 'the', 'names', 'of', 'the', 'author', 'and', 'publisher', 'for', 'the', 'goodreads', 'dataset.', 'the', 'generated', 'description', 'was', 'then', 'compared', 'with', 'the', 'scraped', 'descriptions', 'using', 'a', 'combination', 'of', 'top', 'hits,', 'mrr,', 'and', 'ndcg', 'as', 'evaluation', 'metrics.', 'the', 'results', 'demonstrated', 'that', 'llm-based', 'movie', 'description', 'generation', 'exhibits', 'significant', 'promise,', 'with', 'results', 'comparable', 'to', 'the', 'ones', 'obtained', 'by', 'web-scraped', 'descriptions.']}\n"
     ]
    }
   ],
   "source": [
    "termes = {file_name: txt.lower().split() for file_name, txt in txt_contents.items()}\n",
    "print(termes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query', 'reformulation(qr)', 'is', 'a', 'set', 'of', 'techniques', 'used', 'to', 'transform', 'a', 'user’s', 'original', 'search', 'query', 'to', 'a', 'text', 'that', 'better', 'aligns', 'with', 'the', 'user’s', 'intent', 'and', 'improves', 'their', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'has', 'been', 'shown', 'to', 'be', 'a', 'promising', 'approach', 'due', 'to', 'its', 'ability', 'to', 'exploit', 'knowledge', 'inherent', 'in', 'large', 'language', 'models.', 'by', 'taking', 'inspiration', 'from', 'the', 'success', 'of', 'ensemble', 'prompting', 'strategies', 'which', 'have', 'benefited', 'many', 'tasks,', 'we', 'investigate', 'if', 'they', 'can', 'help', 'improve', 'query', 'reformulation.', 'in', 'this', 'context,', 'we', 'propose', 'an', 'ensemble', 'based', 'prompting', 'technique,', 'genqrensemble', 'which', 'leverages', 'paraphrases', 'of', 'a', 'zero-shot', 'instruction', 'to', 'generate', 'multiple', 'sets', 'of', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance.', 'we', 'further', 'introduce', 'its', 'post-retrieval', 'variant,', 'genqrensemblerf', 'to', 'incorporate', 'pseudo', 'relevant', 'feedback.', 'on', 'evaluations', 'over', 'four', 'ir', 'benchmarks,', 'we', 'find', 'that', 'genqrensemble', 'generates', 'better', 'reformulations', 'with', 'relative', 'ndcg@10', 'improvements', 'up', 'to', '18%', 'and', 'map', 'improvements', 'upto', '24%', 'over', 'the', 'previous', 'zero-shot', 'state-of-art.', 'on', 'the', 'msmarco', 'passage', 'ranking', 'task,', 'genqrensemblerf', 'shows', 'relative', 'gains', 'of', '5%', 'mrr', 'using', 'pseudo-relevance', 'feedback,', 'and', '9%', 'ndcg@10', 'using', 'relevant', 'feedback', 'documents.']\n",
      "['ranking', 'documents', 'using', 'large', 'language', 'models', '(llms)', 'by', 'directly', 'feeding', 'the', 'query', 'and', 'candidate', 'documents', 'into', 'the', 'prompt', 'is', 'an', 'interesting', 'and', 'practical', 'problem.', 'however,', 'researchers', 'have', 'found', 'it', 'difficult', 'to', 'outperform', 'fine-tuned', 'baseline', 'rankers', 'on', 'benchmark', 'datasets.', 'we', 'analyze', 'pointwise', 'and', 'listwise', 'ranking', 'prompts', 'used', 'by', 'existing', 'methods', 'and', 'argue', 'that', 'off-the-shelf', 'llms', 'do', 'not', 'fully', 'understand', 'these', 'challenging', 'ranking', 'formulations.', 'in', 'this', 'paper,', 'we', 'propose', 'to', 'significantly', 'reduce', 'the', 'burden', 'on', 'llms', 'by', 'using', 'a', 'new', 'technique', 'called', 'pairwise', 'ranking', 'prompting', '(prp).', 'our', 'results', 'are', 'the', 'first', 'in', 'the', 'literature', 'to', 'achieve', 'state-of-the-art', 'ranking', 'performance', 'on', 'standard', 'benchmarks', 'using', 'moderate-sized', 'open-sourced', 'llms.', 'on', 'trec-dl', '2019', 'and', '2020,', 'prp', 'based', 'on', 'the', 'flan-ul2', 'model', 'with', '20b', 'parameters', 'performs', 'favorably', 'with', 'the', 'previous', 'best', 'approach', 'in', 'the', 'literature,', 'which', 'is', 'based', 'on', 'the', 'blackbox', 'commercial', 'gpt-4', 'that', 'has', '50x', '(estimated)', 'model', 'size,', 'while', 'outperforming', 'other', 'llm-based', 'solutions,', 'such', 'as', 'instructgpt', 'which', 'has', '175b', 'parameters,', 'by', 'over', '10%', 'for', 'all', 'ranking', 'metrics.', 'by', 'using', 'the', 'same', 'prompt', 'template', 'on', 'seven', 'beir', 'tasks,', 'prp', 'outperforms', 'supervised', 'baselines', 'and', 'outperforms', 'the', 'blackbox', 'commercial', 'chatgpt', 'solution', 'by', '4.2%', 'and', 'pointwise', 'llm-based', 'solutions', 'by', 'more', 'than', '10%', 'on', 'average', 'ndcg@10.', 'furthermore,', 'we', 'propose', 'several', 'variants', 'of', 'prp', 'to', 'improve', 'efficiency', 'and', 'show', 'that', 'it', 'is', 'possible', 'to', 'achieve', 'competitive', 'results', 'even', 'with', 'linear', 'complexity']\n",
      "['large', 'language', 'models', '(llm)', 'have', 'manifested', 'unparalleled', 'modeling', 'capability', 'on', 'various', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'but', 'the', 'input', 'to', 'these', 'models', 'is', 'mostly', 'limited', 'to', 'plain', 'text,', 'which', 'could', 'be', 'very', 'long', 'and', 'contain', 'noisy', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'to', 'process,', 'and', 'thus', 'may', 'not', 'be', 'efficient', 'enough', 'for', 'recommender', 'systems', 'that', 'require', 'immediate', 'response.', 'in', 'llm-based', 'recommendation', 'models,', 'user', 'and', 'item', 'ids', 'are', 'usually', 'filled', 'in', 'a', 'template', '(i.e.,', 'discrete', 'prompt)', 'to', 'allow', 'the', 'models', 'to', 'understand', 'a', 'given', 'task,', 'but', 'the', 'models', 'usually', 'need', 'extensive', 'fine-tuning', 'to', 'bridge', 'the', 'user/item', 'ids', 'and', 'the', 'template', 'words', 'and', 'to', 'unleash', 'the', 'power', 'of', 'llm', 'for', 'recommendation.', 'to', 'address', 'the', 'problems,', 'we', 'propose', 'to', 'distill', 'the', 'discrete', 'prompt', 'for', 'a', 'specific', 'task', 'to', 'a', 'set', 'of', 'continuous', 'prompt', 'vectors', 'so', 'as', 'to', 'bridge', 'ids', 'and', 'words', 'and', 'to', 'reduce', 'the', 'inference', 'time.', 'we', 'also', 'design', 'a', 'training', 'strategy', 'with', 'an', 'attempt', 'to', 'improve', 'the', 'efficiency', 'of', 'training', 'these', 'models.', 'experimental', 'results', 'on', 'three', 'real-world', 'datasets', 'demonstrate', 'the', 'effectiveness', 'of', 'our', 'prompt', 'distillation', '(pod)', 'approach', 'on', 'both', 'sequential', 'recommendation', 'and', 'top-n', 'recommendation', 'tasks.', 'although', 'the', 'training', 'efficiency', 'can', 'be', 'significantly', 'improved,', 'the', 'improvement', 'of', 'inference', 'efficiency', 'is', 'limited.', 'this', 'finding', 'may', 'inspire', 'researchers', 'in', 'the', 'community', 'to', 'further', 'improve', 'the', 'inference', 'efficiency', 'of', 'llm-based', 'recommendation', 'models.']\n",
      "['query', 'reformulation', 'is', 'a', 'well-known', 'problem', 'in', 'information', 'retrieval', '(ir)', 'aimed', 'at', 'enhancing', 'single', 'search', 'successful', 'completion', 'rate', 'by', 'automatically', 'modifying', \"user's\", 'input', 'query.', 'recent', 'methods', 'leverage', 'large', 'language', 'models', '(llms)', 'to', 'improve', 'query', 'reformulation,', 'but', 'often', 'generate', 'limited', 'and', 'redundant', 'expansions,', 'potentially', 'constraining', 'their', 'effectiveness', 'in', 'capturing', 'diverse', 'intents.', 'in', 'this', 'paper,', 'we', 'propose', 'gencrf:', 'a', 'generative', 'clustering', 'and', 'reformulation', 'framework', 'to', 'capture', 'diverse', 'intentions', 'adaptively', 'based', 'on', 'multiple', 'differentiated,', 'well-generated', 'queries', 'in', 'the', 'retrieval', 'phase', 'for', 'the', 'first', 'time.', 'gencrf', 'leverages', 'llms', 'to', 'generate', 'variable', 'queries', 'from', 'the', 'initial', 'query', 'using', 'customized', 'prompts,', 'then', 'clusters', 'them', 'into', 'groups', 'to', 'distinctly', 'represent', 'diverse', 'intents.', 'furthermore,', 'the', 'framework', 'explores', 'to', 'combine', 'diverse', 'intents', 'query', 'with', 'innovative', 'weighted', 'aggregation', 'strategies', 'to', 'optimize', 'retrieval', 'performance', 'and', 'crucially', 'integrates', 'a', 'novel', 'query', 'evaluation', 'rewarding', 'model', '(qerm)', 'to', 'refine', 'the', 'process', 'through', 'feedback', 'loops.', 'empirical', 'experiments', 'on', 'the', 'beir', 'benchmark', 'demonstrate', 'that', 'gencrf', 'achieves', 'state-of-the-art', 'performance,', 'surpassing', 'previous', 'query', 'reformulation', 'sotas', 'by', 'up', 'to', '12%', 'on', 'ndcg@10.', 'these', 'techniques', 'can', 'be', 'adapted', 'to', 'various', 'llms,', 'significantly', 'boosting', 'retriever', 'performance', 'and', 'advancing', 'the', 'field', 'of', 'information', 'retrieval.']\n",
      "['session', 'search', 'involves', 'a', 'series', 'of', 'interactive', 'queries', 'and', 'actions', 'to', 'fulfill', \"user's\", 'complex', 'information', 'need.', 'current', 'strategies', 'typically', 'prioritize', 'sequential', 'modeling', 'for', 'deep', 'semantic', 'understanding,', 'overlooking', 'the', 'graph', 'structure', 'in', 'interactions.', 'while', 'some', 'approaches', 'focus', 'on', 'capturing', 'structural', 'information,', 'they', 'use', 'a', 'generalized', 'representation', 'for', 'documents,', 'neglecting', 'the', 'word-level', 'semantic', 'modeling.', 'in', 'this', 'paper,', 'we', 'propose', 'symbolic', 'graph', 'ranker', '(sgr),', 'which', 'aims', 'to', 'take', 'advantage', 'of', 'both', 'text-based', 'and', 'graph-based', 'approaches', 'by', 'leveraging', 'the', 'power', 'of', 'recent', 'large', 'language', 'models', '(llms).', 'concretely,', 'we', 'first', 'introduce', 'a', 'set', 'of', 'symbolic', 'grammar', 'rules', 'to', 'convert', 'session', 'graph', 'into', 'text.', 'this', 'allows', 'integrating', 'session', 'history,', 'interaction', 'process,', 'and', 'task', 'instruction', 'seamlessly', 'as', 'inputs', 'for', 'the', 'llm.', 'moreover,', 'given', 'the', 'natural', 'discrepancy', 'between', 'llms', 'pre-trained', 'on', 'textual', 'corpora,', 'and', 'the', 'symbolic', 'language', 'we', 'produce', 'using', 'our', 'graph-to-text', 'grammar,', 'our', 'objective', 'is', 'to', 'enhance', \"llms'\", 'ability', 'to', 'capture', 'graph', 'structures', 'within', 'a', 'textual', 'format.', 'to', 'achieve', 'this,', 'we', 'introduce', 'a', 'set', 'of', 'self-supervised', 'symbolic', 'learning', 'tasks', 'including', 'link', 'prediction,', 'node', 'content', 'generation,', 'and', 'generative', 'contrastive', 'learning,', 'to', 'enable', 'llms', 'to', 'capture', 'the', 'topological', 'information', 'from', 'coarse-grained', 'to', 'fine-grained.', 'experiment', 'results', 'and', 'comprehensive', 'analysis', 'on', 'two', 'benchmark', 'datasets,', 'aol', 'and', 'tiangong-st,', 'confirm', 'the', 'superiority', 'of', 'our', 'approach.', 'our', 'paradigm', 'also', 'offers', 'a', 'novel', 'and', 'effective', 'methodology', 'that', 'bridges', 'the', 'gap', 'between', 'traditional', 'search', 'strategies', 'and', 'modern', 'llms.']\n",
      "['the', 'description', 'of', 'an', 'item', 'plays', 'a', 'pivotal', 'role', 'in', 'providing', 'concise', 'and', 'informative', 'summaries', 'to', 'captivate', 'potential', 'viewers', 'and', 'is', 'essential', 'for', 'recommendation', 'systems.', 'traditionally,', 'such', 'descriptions', 'were', 'obtained', 'through', 'manual', 'web', 'scraping', 'techniques,', 'which', 'are', 'time-consuming', 'and', 'susceptible', 'to', 'data', 'inconsistencies.', 'in', 'recent', 'years,', 'large', 'language', 'models', '(llms),', 'such', 'as', 'gpt-3.5,', 'and', 'open', 'source', 'llms', 'like', 'alpaca', 'have', 'emerged', 'as', 'powerful', 'tools', 'for', 'natural', 'language', 'processing', 'tasks.', 'in', 'this', 'paper,', 'we', 'have', 'explored', 'how', 'we', 'can', 'use', 'llms', 'to', 'generate', 'detailed', 'descriptions', 'of', 'the', 'items.', 'to', 'conduct', 'the', 'study,', 'we', 'have', 'used', 'the', 'movielens', '1m', 'dataset', 'comprising', 'movie', 'titles', 'and', 'the', 'goodreads', 'dataset', 'consisting', 'of', 'names', 'of', 'books', 'and', 'subsequently,', 'an', 'open-sourced', 'llm,', 'alpaca,', 'was', 'prompted', 'with', 'few-shot', 'prompting', 'on', 'this', 'dataset', 'to', 'generate', 'detailed', 'movie', 'descriptions', 'considering', 'multiple', 'features', 'like', 'the', 'names', 'of', 'the', 'cast', 'and', 'directors', 'for', 'the', 'ml', 'dataset', 'and', 'the', 'names', 'of', 'the', 'author', 'and', 'publisher', 'for', 'the', 'goodreads', 'dataset.', 'the', 'generated', 'description', 'was', 'then', 'compared', 'with', 'the', 'scraped', 'descriptions', 'using', 'a', 'combination', 'of', 'top', 'hits,', 'mrr,', 'and', 'ndcg', 'as', 'evaluation', 'metrics.', 'the', 'results', 'demonstrated', 'that', 'llm-based', 'movie', 'description', 'generation', 'exhibits', 'significant', 'promise,', 'with', 'results', 'comparable', 'to', 'the', 'ones', 'obtained', 'by', 'web-scraped', 'descriptions.']\n"
     ]
    }
   ],
   "source": [
    "termes1 = txt1.lower().split()\n",
    "print(termes1)\n",
    "termes2 = txt2.lower().split()\n",
    "print(termes2)\n",
    "termes3 = txt3.lower().split()\n",
    "print(termes3)\n",
    "termes4 = txt4.lower().split()\n",
    "print(termes4)\n",
    "termes5 = txt5.lower().split()\n",
    "print(termes5)\n",
    "termes6 = txt6.lower().split()\n",
    "print(termes6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D1': ['query', 'reformulation(qr)', 'set', 'techniques', 'used', 'transform', 'user’s', 'original', 'search', 'query', 'text', 'better', 'aligns', 'user’s', 'intent', 'improves', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'promising', 'approach', 'due', 'ability', 'exploit', 'knowledge', 'inherent', 'large', 'language', 'models.', 'taking', 'inspiration', 'success', 'ensemble', 'prompting', 'strategies', 'benefited', 'many', 'tasks,', 'investigate', 'help', 'improve', 'query', 'reformulation.', 'context,', 'propose', 'ensemble', 'based', 'prompting', 'technique,', 'genqrensemble', 'leverages', 'paraphrases', 'zero-shot', 'instruction', 'generate', 'multiple', 'sets', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance.', 'introduce', 'post-retrieval', 'variant,', 'genqrensemblerf', 'incorporate', 'pseudo', 'relevant', 'feedback.', 'evaluations', 'four', 'ir', 'benchmarks,', 'find', 'genqrensemble', 'generates', 'better', 'reformulations', 'relative', 'ndcg@10', 'improvements', '18%', 'map', 'improvements', 'upto', '24%', 'previous', 'zero-shot', 'state-of-art.', 'msmarco', 'passage', 'ranking', 'task,', 'genqrensemblerf', 'shows', 'relative', 'gains', '5%', 'mrr', 'using', 'pseudo-relevance', 'feedback,', '9%', 'ndcg@10', 'using', 'relevant', 'feedback', 'documents.'], 'D2': ['ranking', 'documents', 'using', 'large', 'language', 'models', '(llms)', 'directly', 'feeding', 'query', 'candidate', 'documents', 'prompt', 'interesting', 'practical', 'problem.', 'however,', 'researchers', 'found', 'difficult', 'outperform', 'fine-tuned', 'baseline', 'rankers', 'benchmark', 'datasets.', 'analyze', 'pointwise', 'listwise', 'ranking', 'prompts', 'used', 'existing', 'methods', 'argue', 'off-the-shelf', 'llms', 'fully', 'understand', 'challenging', 'ranking', 'formulations.', 'paper,', 'propose', 'significantly', 'reduce', 'burden', 'llms', 'using', 'new', 'technique', 'called', 'pairwise', 'ranking', 'prompting', '(prp).', 'results', 'first', 'literature', 'achieve', 'state-of-the-art', 'ranking', 'performance', 'standard', 'benchmarks', 'using', 'moderate-sized', 'open-sourced', 'llms.', 'trec-dl', '2019', '2020,', 'prp', 'based', 'flan-ul2', 'model', '20b', 'parameters', 'performs', 'favorably', 'previous', 'best', 'approach', 'literature,', 'based', 'blackbox', 'commercial', 'gpt-4', '50x', '(estimated)', 'model', 'size,', 'outperforming', 'llm-based', 'solutions,', 'instructgpt', '175b', 'parameters,', '10%', 'ranking', 'metrics.', 'using', 'prompt', 'template', 'seven', 'beir', 'tasks,', 'prp', 'outperforms', 'supervised', 'baselines', 'outperforms', 'blackbox', 'commercial', 'chatgpt', 'solution', '4.2%', 'pointwise', 'llm-based', 'solutions', '10%', 'average', 'ndcg@10.', 'furthermore,', 'propose', 'several', 'variants', 'prp', 'improve', 'efficiency', 'show', 'possible', 'achieve', 'competitive', 'results', 'even', 'linear', 'complexity'], 'D3': ['large', 'language', 'models', '(llm)', 'manifested', 'unparalleled', 'modeling', 'capability', 'various', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'input', 'models', 'mostly', 'limited', 'plain', 'text,', 'could', 'long', 'contain', 'noisy', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'process,', 'thus', 'may', 'efficient', 'enough', 'recommender', 'systems', 'require', 'immediate', 'response.', 'llm-based', 'recommendation', 'models,', 'user', 'item', 'ids', 'usually', 'filled', 'template', '(i.e.,', 'discrete', 'prompt)', 'allow', 'models', 'understand', 'given', 'task,', 'models', 'usually', 'need', 'extensive', 'fine-tuning', 'bridge', 'user/item', 'ids', 'template', 'words', 'unleash', 'power', 'llm', 'recommendation.', 'address', 'problems,', 'propose', 'distill', 'discrete', 'prompt', 'specific', 'task', 'set', 'continuous', 'prompt', 'vectors', 'bridge', 'ids', 'words', 'reduce', 'inference', 'time.', 'also', 'design', 'training', 'strategy', 'attempt', 'improve', 'efficiency', 'training', 'models.', 'experimental', 'results', 'three', 'real-world', 'datasets', 'demonstrate', 'effectiveness', 'prompt', 'distillation', '(pod)', 'approach', 'sequential', 'recommendation', 'top-n', 'recommendation', 'tasks.', 'although', 'training', 'efficiency', 'significantly', 'improved,', 'improvement', 'inference', 'efficiency', 'limited.', 'finding', 'may', 'inspire', 'researchers', 'community', 'improve', 'inference', 'efficiency', 'llm-based', 'recommendation', 'models.'], 'D4': ['query', 'reformulation', 'well-known', 'problem', 'information', 'retrieval', '(ir)', 'aimed', 'enhancing', 'single', 'search', 'successful', 'completion', 'rate', 'automatically', 'modifying', \"user's\", 'input', 'query.', 'recent', 'methods', 'leverage', 'large', 'language', 'models', '(llms)', 'improve', 'query', 'reformulation,', 'often', 'generate', 'limited', 'redundant', 'expansions,', 'potentially', 'constraining', 'effectiveness', 'capturing', 'diverse', 'intents.', 'paper,', 'propose', 'gencrf:', 'generative', 'clustering', 'reformulation', 'framework', 'capture', 'diverse', 'intentions', 'adaptively', 'based', 'multiple', 'differentiated,', 'well-generated', 'queries', 'retrieval', 'phase', 'first', 'time.', 'gencrf', 'leverages', 'llms', 'generate', 'variable', 'queries', 'initial', 'query', 'using', 'customized', 'prompts,', 'clusters', 'groups', 'distinctly', 'represent', 'diverse', 'intents.', 'furthermore,', 'framework', 'explores', 'combine', 'diverse', 'intents', 'query', 'innovative', 'weighted', 'aggregation', 'strategies', 'optimize', 'retrieval', 'performance', 'crucially', 'integrates', 'novel', 'query', 'evaluation', 'rewarding', 'model', '(qerm)', 'refine', 'process', 'feedback', 'loops.', 'empirical', 'experiments', 'beir', 'benchmark', 'demonstrate', 'gencrf', 'achieves', 'state-of-the-art', 'performance,', 'surpassing', 'previous', 'query', 'reformulation', 'sotas', '12%', 'ndcg@10.', 'techniques', 'adapted', 'various', 'llms,', 'significantly', 'boosting', 'retriever', 'performance', 'advancing', 'field', 'information', 'retrieval.'], 'D5': ['session', 'search', 'involves', 'series', 'interactive', 'queries', 'actions', 'fulfill', \"user's\", 'complex', 'information', 'need.', 'current', 'strategies', 'typically', 'prioritize', 'sequential', 'modeling', 'deep', 'semantic', 'understanding,', 'overlooking', 'graph', 'structure', 'interactions.', 'approaches', 'focus', 'capturing', 'structural', 'information,', 'use', 'generalized', 'representation', 'documents,', 'neglecting', 'word-level', 'semantic', 'modeling.', 'paper,', 'propose', 'symbolic', 'graph', 'ranker', '(sgr),', 'aims', 'take', 'advantage', 'text-based', 'graph-based', 'approaches', 'leveraging', 'power', 'recent', 'large', 'language', 'models', '(llms).', 'concretely,', 'first', 'introduce', 'set', 'symbolic', 'grammar', 'rules', 'convert', 'session', 'graph', 'text.', 'allows', 'integrating', 'session', 'history,', 'interaction', 'process,', 'task', 'instruction', 'seamlessly', 'inputs', 'llm.', 'moreover,', 'given', 'natural', 'discrepancy', 'llms', 'pre-trained', 'textual', 'corpora,', 'symbolic', 'language', 'produce', 'using', 'graph-to-text', 'grammar,', 'objective', 'enhance', \"llms'\", 'ability', 'capture', 'graph', 'structures', 'within', 'textual', 'format.', 'achieve', 'this,', 'introduce', 'set', 'self-supervised', 'symbolic', 'learning', 'tasks', 'including', 'link', 'prediction,', 'node', 'content', 'generation,', 'generative', 'contrastive', 'learning,', 'enable', 'llms', 'capture', 'topological', 'information', 'coarse-grained', 'fine-grained.', 'experiment', 'results', 'comprehensive', 'analysis', 'two', 'benchmark', 'datasets,', 'aol', 'tiangong-st,', 'confirm', 'superiority', 'approach.', 'paradigm', 'also', 'offers', 'novel', 'effective', 'methodology', 'bridges', 'gap', 'traditional', 'search', 'strategies', 'modern', 'llms.'], 'D6': ['description', 'item', 'plays', 'pivotal', 'role', 'providing', 'concise', 'informative', 'summaries', 'captivate', 'potential', 'viewers', 'essential', 'recommendation', 'systems.', 'traditionally,', 'descriptions', 'obtained', 'manual', 'web', 'scraping', 'techniques,', 'time-consuming', 'susceptible', 'data', 'inconsistencies.', 'recent', 'years,', 'large', 'language', 'models', '(llms),', 'gpt-3.5,', 'open', 'source', 'llms', 'like', 'alpaca', 'emerged', 'powerful', 'tools', 'natural', 'language', 'processing', 'tasks.', 'paper,', 'explored', 'use', 'llms', 'generate', 'detailed', 'descriptions', 'items.', 'conduct', 'study,', 'used', 'movielens', '1m', 'dataset', 'comprising', 'movie', 'titles', 'goodreads', 'dataset', 'consisting', 'names', 'books', 'subsequently,', 'open-sourced', 'llm,', 'alpaca,', 'prompted', 'few-shot', 'prompting', 'dataset', 'generate', 'detailed', 'movie', 'descriptions', 'considering', 'multiple', 'features', 'like', 'names', 'cast', 'directors', 'ml', 'dataset', 'names', 'author', 'publisher', 'goodreads', 'dataset.', 'generated', 'description', 'compared', 'scraped', 'descriptions', 'using', 'combination', 'top', 'hits,', 'mrr,', 'ndcg', 'evaluation', 'metrics.', 'results', 'demonstrated', 'llm-based', 'movie', 'description', 'generation', 'exhibits', 'significant', 'promise,', 'results', 'comparable', 'ones', 'obtained', 'web-scraped', 'descriptions.']}\n"
     ]
    }
   ],
   "source": [
    "MotsVides = stopwords.words('english')\n",
    "TermesSansMotsVides = {file_name: [word for word in txt if word not in MotsVides] for file_name, txt in termes.items()}\n",
    "print(TermesSansMotsVides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query', 'reformulation(qr)', 'set', 'techniques', 'used', 'transform', 'user’s', 'original', 'search', 'query', 'text', 'better', 'aligns', 'user’s', 'intent', 'improves', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'promising', 'approach', 'due', 'ability', 'exploit', 'knowledge', 'inherent', 'large', 'language', 'models.', 'taking', 'inspiration', 'success', 'ensemble', 'prompting', 'strategies', 'benefited', 'many', 'tasks,', 'investigate', 'help', 'improve', 'query', 'reformulation.', 'context,', 'propose', 'ensemble', 'based', 'prompting', 'technique,', 'genqrensemble', 'leverages', 'paraphrases', 'zero-shot', 'instruction', 'generate', 'multiple', 'sets', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance.', 'introduce', 'post-retrieval', 'variant,', 'genqrensemblerf', 'incorporate', 'pseudo', 'relevant', 'feedback.', 'evaluations', 'four', 'ir', 'benchmarks,', 'find', 'genqrensemble', 'generates', 'better', 'reformulations', 'relative', 'ndcg@10', 'improvements', '18%', 'map', 'improvements', 'upto', '24%', 'previous', 'zero-shot', 'state-of-art.', 'msmarco', 'passage', 'ranking', 'task,', 'genqrensemblerf', 'shows', 'relative', 'gains', '5%', 'mrr', 'using', 'pseudo-relevance', 'feedback,', '9%', 'ndcg@10', 'using', 'relevant', 'feedback', 'documents.']\n",
      "['ranking', 'documents', 'using', 'large', 'language', 'models', '(llms)', 'directly', 'feeding', 'query', 'candidate', 'documents', 'prompt', 'interesting', 'practical', 'problem.', 'however,', 'researchers', 'found', 'difficult', 'outperform', 'fine-tuned', 'baseline', 'rankers', 'benchmark', 'datasets.', 'analyze', 'pointwise', 'listwise', 'ranking', 'prompts', 'used', 'existing', 'methods', 'argue', 'off-the-shelf', 'llms', 'fully', 'understand', 'challenging', 'ranking', 'formulations.', 'paper,', 'propose', 'significantly', 'reduce', 'burden', 'llms', 'using', 'new', 'technique', 'called', 'pairwise', 'ranking', 'prompting', '(prp).', 'results', 'first', 'literature', 'achieve', 'state-of-the-art', 'ranking', 'performance', 'standard', 'benchmarks', 'using', 'moderate-sized', 'open-sourced', 'llms.', 'trec-dl', '2019', '2020,', 'prp', 'based', 'flan-ul2', 'model', '20b', 'parameters', 'performs', 'favorably', 'previous', 'best', 'approach', 'literature,', 'based', 'blackbox', 'commercial', 'gpt-4', '50x', '(estimated)', 'model', 'size,', 'outperforming', 'llm-based', 'solutions,', 'instructgpt', '175b', 'parameters,', '10%', 'ranking', 'metrics.', 'using', 'prompt', 'template', 'seven', 'beir', 'tasks,', 'prp', 'outperforms', 'supervised', 'baselines', 'outperforms', 'blackbox', 'commercial', 'chatgpt', 'solution', '4.2%', 'pointwise', 'llm-based', 'solutions', '10%', 'average', 'ndcg@10.', 'furthermore,', 'propose', 'several', 'variants', 'prp', 'improve', 'efficiency', 'show', 'possible', 'achieve', 'competitive', 'results', 'even', 'linear', 'complexity']\n",
      "['large', 'language', 'models', '(llm)', 'manifested', 'unparalleled', 'modeling', 'capability', 'various', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'input', 'models', 'mostly', 'limited', 'plain', 'text,', 'could', 'long', 'contain', 'noisy', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'process,', 'thus', 'may', 'efficient', 'enough', 'recommender', 'systems', 'require', 'immediate', 'response.', 'llm-based', 'recommendation', 'models,', 'user', 'item', 'ids', 'usually', 'filled', 'template', '(i.e.,', 'discrete', 'prompt)', 'allow', 'models', 'understand', 'given', 'task,', 'models', 'usually', 'need', 'extensive', 'fine-tuning', 'bridge', 'user/item', 'ids', 'template', 'words', 'unleash', 'power', 'llm', 'recommendation.', 'address', 'problems,', 'propose', 'distill', 'discrete', 'prompt', 'specific', 'task', 'set', 'continuous', 'prompt', 'vectors', 'bridge', 'ids', 'words', 'reduce', 'inference', 'time.', 'also', 'design', 'training', 'strategy', 'attempt', 'improve', 'efficiency', 'training', 'models.', 'experimental', 'results', 'three', 'real-world', 'datasets', 'demonstrate', 'effectiveness', 'prompt', 'distillation', '(pod)', 'approach', 'sequential', 'recommendation', 'top-n', 'recommendation', 'tasks.', 'although', 'training', 'efficiency', 'significantly', 'improved,', 'improvement', 'inference', 'efficiency', 'limited.', 'finding', 'may', 'inspire', 'researchers', 'community', 'improve', 'inference', 'efficiency', 'llm-based', 'recommendation', 'models.']\n",
      "['query', 'reformulation', 'well-known', 'problem', 'information', 'retrieval', '(ir)', 'aimed', 'enhancing', 'single', 'search', 'successful', 'completion', 'rate', 'automatically', 'modifying', \"user's\", 'input', 'query.', 'recent', 'methods', 'leverage', 'large', 'language', 'models', '(llms)', 'improve', 'query', 'reformulation,', 'often', 'generate', 'limited', 'redundant', 'expansions,', 'potentially', 'constraining', 'effectiveness', 'capturing', 'diverse', 'intents.', 'paper,', 'propose', 'gencrf:', 'generative', 'clustering', 'reformulation', 'framework', 'capture', 'diverse', 'intentions', 'adaptively', 'based', 'multiple', 'differentiated,', 'well-generated', 'queries', 'retrieval', 'phase', 'first', 'time.', 'gencrf', 'leverages', 'llms', 'generate', 'variable', 'queries', 'initial', 'query', 'using', 'customized', 'prompts,', 'clusters', 'groups', 'distinctly', 'represent', 'diverse', 'intents.', 'furthermore,', 'framework', 'explores', 'combine', 'diverse', 'intents', 'query', 'innovative', 'weighted', 'aggregation', 'strategies', 'optimize', 'retrieval', 'performance', 'crucially', 'integrates', 'novel', 'query', 'evaluation', 'rewarding', 'model', '(qerm)', 'refine', 'process', 'feedback', 'loops.', 'empirical', 'experiments', 'beir', 'benchmark', 'demonstrate', 'gencrf', 'achieves', 'state-of-the-art', 'performance,', 'surpassing', 'previous', 'query', 'reformulation', 'sotas', '12%', 'ndcg@10.', 'techniques', 'adapted', 'various', 'llms,', 'significantly', 'boosting', 'retriever', 'performance', 'advancing', 'field', 'information', 'retrieval.']\n",
      "['session', 'search', 'involves', 'series', 'interactive', 'queries', 'actions', 'fulfill', \"user's\", 'complex', 'information', 'need.', 'current', 'strategies', 'typically', 'prioritize', 'sequential', 'modeling', 'deep', 'semantic', 'understanding,', 'overlooking', 'graph', 'structure', 'interactions.', 'approaches', 'focus', 'capturing', 'structural', 'information,', 'use', 'generalized', 'representation', 'documents,', 'neglecting', 'word-level', 'semantic', 'modeling.', 'paper,', 'propose', 'symbolic', 'graph', 'ranker', '(sgr),', 'aims', 'take', 'advantage', 'text-based', 'graph-based', 'approaches', 'leveraging', 'power', 'recent', 'large', 'language', 'models', '(llms).', 'concretely,', 'first', 'introduce', 'set', 'symbolic', 'grammar', 'rules', 'convert', 'session', 'graph', 'text.', 'allows', 'integrating', 'session', 'history,', 'interaction', 'process,', 'task', 'instruction', 'seamlessly', 'inputs', 'llm.', 'moreover,', 'given', 'natural', 'discrepancy', 'llms', 'pre-trained', 'textual', 'corpora,', 'symbolic', 'language', 'produce', 'using', 'graph-to-text', 'grammar,', 'objective', 'enhance', \"llms'\", 'ability', 'capture', 'graph', 'structures', 'within', 'textual', 'format.', 'achieve', 'this,', 'introduce', 'set', 'self-supervised', 'symbolic', 'learning', 'tasks', 'including', 'link', 'prediction,', 'node', 'content', 'generation,', 'generative', 'contrastive', 'learning,', 'enable', 'llms', 'capture', 'topological', 'information', 'coarse-grained', 'fine-grained.', 'experiment', 'results', 'comprehensive', 'analysis', 'two', 'benchmark', 'datasets,', 'aol', 'tiangong-st,', 'confirm', 'superiority', 'approach.', 'paradigm', 'also', 'offers', 'novel', 'effective', 'methodology', 'bridges', 'gap', 'traditional', 'search', 'strategies', 'modern', 'llms.']\n",
      "['description', 'item', 'plays', 'pivotal', 'role', 'providing', 'concise', 'informative', 'summaries', 'captivate', 'potential', 'viewers', 'essential', 'recommendation', 'systems.', 'traditionally,', 'descriptions', 'obtained', 'manual', 'web', 'scraping', 'techniques,', 'time-consuming', 'susceptible', 'data', 'inconsistencies.', 'recent', 'years,', 'large', 'language', 'models', '(llms),', 'gpt-3.5,', 'open', 'source', 'llms', 'like', 'alpaca', 'emerged', 'powerful', 'tools', 'natural', 'language', 'processing', 'tasks.', 'paper,', 'explored', 'use', 'llms', 'generate', 'detailed', 'descriptions', 'items.', 'conduct', 'study,', 'used', 'movielens', '1m', 'dataset', 'comprising', 'movie', 'titles', 'goodreads', 'dataset', 'consisting', 'names', 'books', 'subsequently,', 'open-sourced', 'llm,', 'alpaca,', 'prompted', 'few-shot', 'prompting', 'dataset', 'generate', 'detailed', 'movie', 'descriptions', 'considering', 'multiple', 'features', 'like', 'names', 'cast', 'directors', 'ml', 'dataset', 'names', 'author', 'publisher', 'goodreads', 'dataset.', 'generated', 'description', 'compared', 'scraped', 'descriptions', 'using', 'combination', 'top', 'hits,', 'mrr,', 'ndcg', 'evaluation', 'metrics.', 'results', 'demonstrated', 'llm-based', 'movie', 'description', 'generation', 'exhibits', 'significant', 'promise,', 'results', 'comparable', 'ones', 'obtained', 'web-scraped', 'descriptions.']\n"
     ]
    }
   ],
   "source": [
    "MotsVides = stopwords.words('english')\n",
    "TermesSansMotsVides1 = [terme for terme in termes1 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides2 = [terme for terme in termes2 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides3 = [terme for terme in termes3 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides4 = [terme for terme in termes4 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides5 = [terme for terme in termes5 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides6 = [terme for terme in termes6 if terme.lower() not in MotsVides]\n",
    "print(TermesSansMotsVides1)\n",
    "print(TermesSansMotsVides2)\n",
    "print(TermesSansMotsVides3)\n",
    "print(TermesSansMotsVides4)\n",
    "print(TermesSansMotsVides5)\n",
    "print(TermesSansMotsVides6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D1': ['queri', 'reformulation(qr)', 'set', 'techniqu', 'use', 'transform', 'user’', 'origin', 'search', 'queri', 'text', 'better', 'align', 'user’', 'intent', 'improv', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'promis', 'approach', 'due', 'abil', 'exploit', 'knowledg', 'inher', 'larg', 'languag', 'models.', 'take', 'inspir', 'success', 'ensembl', 'prompt', 'strategi', 'benefit', 'mani', 'tasks,', 'investig', 'help', 'improv', 'queri', 'reformulation.', 'context,', 'propos', 'ensembl', 'base', 'prompt', 'technique,', 'genqrensembl', 'leverag', 'paraphras', 'zero-shot', 'instruct', 'gener', 'multipl', 'set', 'keyword', 'ultim', 'improv', 'retriev', 'performance.', 'introduc', 'post-retriev', 'variant,', 'genqrensemblerf', 'incorpor', 'pseudo', 'relev', 'feedback.', 'evalu', 'four', 'ir', 'benchmarks,', 'find', 'genqrensembl', 'gener', 'better', 'reformul', 'rel', 'ndcg@10', 'improv', '18%', 'map', 'improv', 'upto', '24%', 'previou', 'zero-shot', 'state-of-art.', 'msmarco', 'passag', 'rank', 'task,', 'genqrensemblerf', 'show', 'rel', 'gain', '5%', 'mrr', 'use', 'pseudo-relev', 'feedback,', '9%', 'ndcg@10', 'use', 'relev', 'feedback', 'documents.'], 'D2': ['rank', 'document', 'use', 'larg', 'languag', 'model', '(llms)', 'directli', 'feed', 'queri', 'candid', 'document', 'prompt', 'interest', 'practic', 'problem.', 'however,', 'research', 'found', 'difficult', 'outperform', 'fine-tun', 'baselin', 'ranker', 'benchmark', 'datasets.', 'analyz', 'pointwis', 'listwis', 'rank', 'prompt', 'use', 'exist', 'method', 'argu', 'off-the-shelf', 'llm', 'fulli', 'understand', 'challeng', 'rank', 'formulations.', 'paper,', 'propos', 'significantli', 'reduc', 'burden', 'llm', 'use', 'new', 'techniqu', 'call', 'pairwis', 'rank', 'prompt', '(prp).', 'result', 'first', 'literatur', 'achiev', 'state-of-the-art', 'rank', 'perform', 'standard', 'benchmark', 'use', 'moderate-s', 'open-sourc', 'llms.', 'trec-dl', '2019', '2020,', 'prp', 'base', 'flan-ul2', 'model', '20b', 'paramet', 'perform', 'favor', 'previou', 'best', 'approach', 'literature,', 'base', 'blackbox', 'commerci', 'gpt-4', '50x', '(estimated)', 'model', 'size,', 'outperform', 'llm-base', 'solutions,', 'instructgpt', '175b', 'parameters,', '10%', 'rank', 'metrics.', 'use', 'prompt', 'templat', 'seven', 'beir', 'tasks,', 'prp', 'outperform', 'supervis', 'baselin', 'outperform', 'blackbox', 'commerci', 'chatgpt', 'solut', '4.2%', 'pointwis', 'llm-base', 'solut', '10%', 'averag', 'ndcg@10.', 'furthermore,', 'propos', 'sever', 'variant', 'prp', 'improv', 'effici', 'show', 'possibl', 'achiev', 'competit', 'result', 'even', 'linear', 'complex'], 'D3': ['larg', 'languag', 'model', '(llm)', 'manifest', 'unparallel', 'model', 'capabl', 'variou', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'input', 'model', 'mostli', 'limit', 'plain', 'text,', 'could', 'long', 'contain', 'noisi', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'process,', 'thu', 'may', 'effici', 'enough', 'recommend', 'system', 'requir', 'immedi', 'response.', 'llm-base', 'recommend', 'models,', 'user', 'item', 'id', 'usual', 'fill', 'templat', '(i.e.,', 'discret', 'prompt)', 'allow', 'model', 'understand', 'given', 'task,', 'model', 'usual', 'need', 'extens', 'fine-tun', 'bridg', 'user/item', 'id', 'templat', 'word', 'unleash', 'power', 'llm', 'recommendation.', 'address', 'problems,', 'propos', 'distil', 'discret', 'prompt', 'specif', 'task', 'set', 'continu', 'prompt', 'vector', 'bridg', 'id', 'word', 'reduc', 'infer', 'time.', 'also', 'design', 'train', 'strategi', 'attempt', 'improv', 'effici', 'train', 'models.', 'experiment', 'result', 'three', 'real-world', 'dataset', 'demonstr', 'effect', 'prompt', 'distil', '(pod)', 'approach', 'sequenti', 'recommend', 'top-n', 'recommend', 'tasks.', 'although', 'train', 'effici', 'significantli', 'improved,', 'improv', 'infer', 'effici', 'limited.', 'find', 'may', 'inspir', 'research', 'commun', 'improv', 'infer', 'effici', 'llm-base', 'recommend', 'models.'], 'D4': ['queri', 'reformul', 'well-known', 'problem', 'inform', 'retriev', '(ir)', 'aim', 'enhanc', 'singl', 'search', 'success', 'complet', 'rate', 'automat', 'modifi', \"user'\", 'input', 'query.', 'recent', 'method', 'leverag', 'larg', 'languag', 'model', '(llms)', 'improv', 'queri', 'reformulation,', 'often', 'gener', 'limit', 'redund', 'expansions,', 'potenti', 'constrain', 'effect', 'captur', 'divers', 'intents.', 'paper,', 'propos', 'gencrf:', 'gener', 'cluster', 'reformul', 'framework', 'captur', 'divers', 'intent', 'adapt', 'base', 'multipl', 'differentiated,', 'well-gener', 'queri', 'retriev', 'phase', 'first', 'time.', 'gencrf', 'leverag', 'llm', 'gener', 'variabl', 'queri', 'initi', 'queri', 'use', 'custom', 'prompts,', 'cluster', 'group', 'distinctli', 'repres', 'divers', 'intents.', 'furthermore,', 'framework', 'explor', 'combin', 'divers', 'intent', 'queri', 'innov', 'weight', 'aggreg', 'strategi', 'optim', 'retriev', 'perform', 'crucial', 'integr', 'novel', 'queri', 'evalu', 'reward', 'model', '(qerm)', 'refin', 'process', 'feedback', 'loops.', 'empir', 'experi', 'beir', 'benchmark', 'demonstr', 'gencrf', 'achiev', 'state-of-the-art', 'performance,', 'surpass', 'previou', 'queri', 'reformul', 'sota', '12%', 'ndcg@10.', 'techniqu', 'adapt', 'variou', 'llms,', 'significantli', 'boost', 'retriev', 'perform', 'advanc', 'field', 'inform', 'retrieval.'], 'D5': ['session', 'search', 'involv', 'seri', 'interact', 'queri', 'action', 'fulfil', \"user'\", 'complex', 'inform', 'need.', 'current', 'strategi', 'typic', 'priorit', 'sequenti', 'model', 'deep', 'semant', 'understanding,', 'overlook', 'graph', 'structur', 'interactions.', 'approach', 'focu', 'captur', 'structur', 'information,', 'use', 'gener', 'represent', 'documents,', 'neglect', 'word-level', 'semant', 'modeling.', 'paper,', 'propos', 'symbol', 'graph', 'ranker', '(sgr),', 'aim', 'take', 'advantag', 'text-bas', 'graph-bas', 'approach', 'leverag', 'power', 'recent', 'larg', 'languag', 'model', '(llms).', 'concretely,', 'first', 'introduc', 'set', 'symbol', 'grammar', 'rule', 'convert', 'session', 'graph', 'text.', 'allow', 'integr', 'session', 'history,', 'interact', 'process,', 'task', 'instruct', 'seamlessli', 'input', 'llm.', 'moreover,', 'given', 'natur', 'discrep', 'llm', 'pre-train', 'textual', 'corpora,', 'symbol', 'languag', 'produc', 'use', 'graph-to-text', 'grammar,', 'object', 'enhanc', \"llms'\", 'abil', 'captur', 'graph', 'structur', 'within', 'textual', 'format.', 'achiev', 'this,', 'introduc', 'set', 'self-supervis', 'symbol', 'learn', 'task', 'includ', 'link', 'prediction,', 'node', 'content', 'generation,', 'gener', 'contrast', 'learning,', 'enabl', 'llm', 'captur', 'topolog', 'inform', 'coarse-grain', 'fine-grained.', 'experi', 'result', 'comprehens', 'analysi', 'two', 'benchmark', 'datasets,', 'aol', 'tiangong-st,', 'confirm', 'superior', 'approach.', 'paradigm', 'also', 'offer', 'novel', 'effect', 'methodolog', 'bridg', 'gap', 'tradit', 'search', 'strategi', 'modern', 'llms.'], 'D6': ['descript', 'item', 'play', 'pivot', 'role', 'provid', 'concis', 'inform', 'summari', 'captiv', 'potenti', 'viewer', 'essenti', 'recommend', 'systems.', 'traditionally,', 'descript', 'obtain', 'manual', 'web', 'scrape', 'techniques,', 'time-consum', 'suscept', 'data', 'inconsistencies.', 'recent', 'years,', 'larg', 'languag', 'model', '(llms),', 'gpt-3.5,', 'open', 'sourc', 'llm', 'like', 'alpaca', 'emerg', 'power', 'tool', 'natur', 'languag', 'process', 'tasks.', 'paper,', 'explor', 'use', 'llm', 'gener', 'detail', 'descript', 'items.', 'conduct', 'study,', 'use', 'movielen', '1m', 'dataset', 'compris', 'movi', 'titl', 'goodread', 'dataset', 'consist', 'name', 'book', 'subsequently,', 'open-sourc', 'llm,', 'alpaca,', 'prompt', 'few-shot', 'prompt', 'dataset', 'gener', 'detail', 'movi', 'descript', 'consid', 'multipl', 'featur', 'like', 'name', 'cast', 'director', 'ml', 'dataset', 'name', 'author', 'publish', 'goodread', 'dataset.', 'gener', 'descript', 'compar', 'scrape', 'descript', 'use', 'combin', 'top', 'hits,', 'mrr,', 'ndcg', 'evalu', 'metrics.', 'result', 'demonstr', 'llm-base', 'movi', 'descript', 'gener', 'exhibit', 'signific', 'promise,', 'result', 'compar', 'one', 'obtain', 'web-scrap', 'descriptions.']}\n"
     ]
    }
   ],
   "source": [
    "TermesNormalisation = {file_name: [Porter.stem(word) for word in txt] for file_name, txt in TermesSansMotsVides.items()}\n",
    "print(TermesNormalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queri', 'reformulation(qr)', 'set', 'techniqu', 'use', 'transform', 'user’', 'origin', 'search', 'queri', 'text', 'better', 'align', 'user’', 'intent', 'improv', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'promis', 'approach', 'due', 'abil', 'exploit', 'knowledg', 'inher', 'larg', 'languag', 'models.', 'take', 'inspir', 'success', 'ensembl', 'prompt', 'strategi', 'benefit', 'mani', 'tasks,', 'investig', 'help', 'improv', 'queri', 'reformulation.', 'context,', 'propos', 'ensembl', 'base', 'prompt', 'technique,', 'genqrensembl', 'leverag', 'paraphras', 'zero-shot', 'instruct', 'gener', 'multipl', 'set', 'keyword', 'ultim', 'improv', 'retriev', 'performance.', 'introduc', 'post-retriev', 'variant,', 'genqrensemblerf', 'incorpor', 'pseudo', 'relev', 'feedback.', 'evalu', 'four', 'ir', 'benchmarks,', 'find', 'genqrensembl', 'gener', 'better', 'reformul', 'rel', 'ndcg@10', 'improv', '18%', 'map', 'improv', 'upto', '24%', 'previou', 'zero-shot', 'state-of-art.', 'msmarco', 'passag', 'rank', 'task,', 'genqrensemblerf', 'show', 'rel', 'gain', '5%', 'mrr', 'use', 'pseudo-relev', 'feedback,', '9%', 'ndcg@10', 'use', 'relev', 'feedback', 'documents.']\n",
      "['rank', 'document', 'use', 'larg', 'languag', 'model', '(llms)', 'directli', 'feed', 'queri', 'candid', 'document', 'prompt', 'interest', 'practic', 'problem.', 'however,', 'research', 'found', 'difficult', 'outperform', 'fine-tun', 'baselin', 'ranker', 'benchmark', 'datasets.', 'analyz', 'pointwis', 'listwis', 'rank', 'prompt', 'use', 'exist', 'method', 'argu', 'off-the-shelf', 'llm', 'fulli', 'understand', 'challeng', 'rank', 'formulations.', 'paper,', 'propos', 'significantli', 'reduc', 'burden', 'llm', 'use', 'new', 'techniqu', 'call', 'pairwis', 'rank', 'prompt', '(prp).', 'result', 'first', 'literatur', 'achiev', 'state-of-the-art', 'rank', 'perform', 'standard', 'benchmark', 'use', 'moderate-s', 'open-sourc', 'llms.', 'trec-dl', '2019', '2020,', 'prp', 'base', 'flan-ul2', 'model', '20b', 'paramet', 'perform', 'favor', 'previou', 'best', 'approach', 'literature,', 'base', 'blackbox', 'commerci', 'gpt-4', '50x', '(estimated)', 'model', 'size,', 'outperform', 'llm-base', 'solutions,', 'instructgpt', '175b', 'parameters,', '10%', 'rank', 'metrics.', 'use', 'prompt', 'templat', 'seven', 'beir', 'tasks,', 'prp', 'outperform', 'supervis', 'baselin', 'outperform', 'blackbox', 'commerci', 'chatgpt', 'solut', '4.2%', 'pointwis', 'llm-base', 'solut', '10%', 'averag', 'ndcg@10.', 'furthermore,', 'propos', 'sever', 'variant', 'prp', 'improv', 'effici', 'show', 'possibl', 'achiev', 'competit', 'result', 'even', 'linear', 'complex']\n",
      "['larg', 'languag', 'model', '(llm)', 'manifest', 'unparallel', 'model', 'capabl', 'variou', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'input', 'model', 'mostli', 'limit', 'plain', 'text,', 'could', 'long', 'contain', 'noisi', 'information.', 'long', 'text', 'could', 'take', 'long', 'time', 'process,', 'thu', 'may', 'effici', 'enough', 'recommend', 'system', 'requir', 'immedi', 'response.', 'llm-base', 'recommend', 'models,', 'user', 'item', 'id', 'usual', 'fill', 'templat', '(i.e.,', 'discret', 'prompt)', 'allow', 'model', 'understand', 'given', 'task,', 'model', 'usual', 'need', 'extens', 'fine-tun', 'bridg', 'user/item', 'id', 'templat', 'word', 'unleash', 'power', 'llm', 'recommendation.', 'address', 'problems,', 'propos', 'distil', 'discret', 'prompt', 'specif', 'task', 'set', 'continu', 'prompt', 'vector', 'bridg', 'id', 'word', 'reduc', 'infer', 'time.', 'also', 'design', 'train', 'strategi', 'attempt', 'improv', 'effici', 'train', 'models.', 'experiment', 'result', 'three', 'real-world', 'dataset', 'demonstr', 'effect', 'prompt', 'distil', '(pod)', 'approach', 'sequenti', 'recommend', 'top-n', 'recommend', 'tasks.', 'although', 'train', 'effici', 'significantli', 'improved,', 'improv', 'infer', 'effici', 'limited.', 'find', 'may', 'inspir', 'research', 'commun', 'improv', 'infer', 'effici', 'llm-base', 'recommend', 'models.']\n",
      "['queri', 'reformul', 'well-known', 'problem', 'inform', 'retriev', '(ir)', 'aim', 'enhanc', 'singl', 'search', 'success', 'complet', 'rate', 'automat', 'modifi', \"user'\", 'input', 'query.', 'recent', 'method', 'leverag', 'larg', 'languag', 'model', '(llms)', 'improv', 'queri', 'reformulation,', 'often', 'gener', 'limit', 'redund', 'expansions,', 'potenti', 'constrain', 'effect', 'captur', 'divers', 'intents.', 'paper,', 'propos', 'gencrf:', 'gener', 'cluster', 'reformul', 'framework', 'captur', 'divers', 'intent', 'adapt', 'base', 'multipl', 'differentiated,', 'well-gener', 'queri', 'retriev', 'phase', 'first', 'time.', 'gencrf', 'leverag', 'llm', 'gener', 'variabl', 'queri', 'initi', 'queri', 'use', 'custom', 'prompts,', 'cluster', 'group', 'distinctli', 'repres', 'divers', 'intents.', 'furthermore,', 'framework', 'explor', 'combin', 'divers', 'intent', 'queri', 'innov', 'weight', 'aggreg', 'strategi', 'optim', 'retriev', 'perform', 'crucial', 'integr', 'novel', 'queri', 'evalu', 'reward', 'model', '(qerm)', 'refin', 'process', 'feedback', 'loops.', 'empir', 'experi', 'beir', 'benchmark', 'demonstr', 'gencrf', 'achiev', 'state-of-the-art', 'performance,', 'surpass', 'previou', 'queri', 'reformul', 'sota', '12%', 'ndcg@10.', 'techniqu', 'adapt', 'variou', 'llms,', 'significantli', 'boost', 'retriev', 'perform', 'advanc', 'field', 'inform', 'retrieval.']\n",
      "['session', 'search', 'involv', 'seri', 'interact', 'queri', 'action', 'fulfil', \"user'\", 'complex', 'inform', 'need.', 'current', 'strategi', 'typic', 'priorit', 'sequenti', 'model', 'deep', 'semant', 'understanding,', 'overlook', 'graph', 'structur', 'interactions.', 'approach', 'focu', 'captur', 'structur', 'information,', 'use', 'gener', 'represent', 'documents,', 'neglect', 'word-level', 'semant', 'modeling.', 'paper,', 'propos', 'symbol', 'graph', 'ranker', '(sgr),', 'aim', 'take', 'advantag', 'text-bas', 'graph-bas', 'approach', 'leverag', 'power', 'recent', 'larg', 'languag', 'model', '(llms).', 'concretely,', 'first', 'introduc', 'set', 'symbol', 'grammar', 'rule', 'convert', 'session', 'graph', 'text.', 'allow', 'integr', 'session', 'history,', 'interact', 'process,', 'task', 'instruct', 'seamlessli', 'input', 'llm.', 'moreover,', 'given', 'natur', 'discrep', 'llm', 'pre-train', 'textual', 'corpora,', 'symbol', 'languag', 'produc', 'use', 'graph-to-text', 'grammar,', 'object', 'enhanc', \"llms'\", 'abil', 'captur', 'graph', 'structur', 'within', 'textual', 'format.', 'achiev', 'this,', 'introduc', 'set', 'self-supervis', 'symbol', 'learn', 'task', 'includ', 'link', 'prediction,', 'node', 'content', 'generation,', 'gener', 'contrast', 'learning,', 'enabl', 'llm', 'captur', 'topolog', 'inform', 'coarse-grain', 'fine-grained.', 'experi', 'result', 'comprehens', 'analysi', 'two', 'benchmark', 'datasets,', 'aol', 'tiangong-st,', 'confirm', 'superior', 'approach.', 'paradigm', 'also', 'offer', 'novel', 'effect', 'methodolog', 'bridg', 'gap', 'tradit', 'search', 'strategi', 'modern', 'llms.']\n",
      "['descript', 'item', 'play', 'pivot', 'role', 'provid', 'concis', 'inform', 'summari', 'captiv', 'potenti', 'viewer', 'essenti', 'recommend', 'systems.', 'traditionally,', 'descript', 'obtain', 'manual', 'web', 'scrape', 'techniques,', 'time-consum', 'suscept', 'data', 'inconsistencies.', 'recent', 'years,', 'larg', 'languag', 'model', '(llms),', 'gpt-3.5,', 'open', 'sourc', 'llm', 'like', 'alpaca', 'emerg', 'power', 'tool', 'natur', 'languag', 'process', 'tasks.', 'paper,', 'explor', 'use', 'llm', 'gener', 'detail', 'descript', 'items.', 'conduct', 'study,', 'use', 'movielen', '1m', 'dataset', 'compris', 'movi', 'titl', 'goodread', 'dataset', 'consist', 'name', 'book', 'subsequently,', 'open-sourc', 'llm,', 'alpaca,', 'prompt', 'few-shot', 'prompt', 'dataset', 'gener', 'detail', 'movi', 'descript', 'consid', 'multipl', 'featur', 'like', 'name', 'cast', 'director', 'ml', 'dataset', 'name', 'author', 'publish', 'goodread', 'dataset.', 'gener', 'descript', 'compar', 'scrape', 'descript', 'use', 'combin', 'top', 'hits,', 'mrr,', 'ndcg', 'evalu', 'metrics.', 'result', 'demonstr', 'llm-base', 'movi', 'descript', 'gener', 'exhibit', 'signific', 'promise,', 'result', 'compar', 'one', 'obtain', 'web-scrap', 'descriptions.']\n"
     ]
    }
   ],
   "source": [
    "TermesNormalisation1 = [Porter.stem(terme) for terme in TermesSansMotsVides1]\n",
    "TermesNormalisation2 = [Porter.stem(terme) for terme in TermesSansMotsVides2]\n",
    "TermesNormalisation3 = [Porter.stem(terme) for terme in TermesSansMotsVides3]\n",
    "TermesNormalisation4 = [Porter.stem(terme) for terme in TermesSansMotsVides4]\n",
    "TermesNormalisation5 = [Porter.stem(terme) for terme in TermesSansMotsVides5]\n",
    "TermesNormalisation6 = [Porter.stem(terme) for terme in TermesSansMotsVides6]\n",
    "\n",
    "print(TermesNormalisation1)\n",
    "print(TermesNormalisation2)\n",
    "print(TermesNormalisation3)\n",
    "print(TermesNormalisation4)\n",
    "print(TermesNormalisation5)\n",
    "print(TermesNormalisation6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"../Index/DescripteursSplitPorter.txt\", mode='w') as f :\n",
    "    for idx, (file_name, termes) in enumerate(TermesNormalisation.items(), start=1):\n",
    "        for terme in termes:\n",
    "            f.write(f'{idx}. ' + terme + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"Index/DescripteursSplitPorter.txt\", mode='w') as f :\n",
    "    for terme in TermesNormalisation1:\n",
    "        f.write('1.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation2:\n",
    "        f.write('2.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation3:\n",
    "        f.write('3.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation4:\n",
    "        f.write('4.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation5:\n",
    "        f.write('5.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation6:\n",
    "        f.write('6.' + terme+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# with open(file=\"Index/InverseSplitPorter.txt\", mode='w') as f :\n",
    "#     for terme in TermesNormalisation1:\n",
    "#         f.write(terme+ '    1' + '\\n')\n",
    "#     for terme in TermesNormalisation2:\n",
    "#         f.write(terme + '   2' +'\\n')\n",
    "#     for terme in TermesNormalisation3:\n",
    "#         f.write(terme + '   3' +'\\n')\n",
    "#     for terme in TermesNormalisation4:\n",
    "#         f.write(terme+ '    4' +'\\n')\n",
    "#     for terme in TermesNormalisation5:\n",
    "#         f.write(terme+ '    5' + '\\n')\n",
    "#     for terme in TermesNormalisation6:\n",
    "#         f.write(terme + '   6' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_termes1 = sorted(TermesNormalisation1)\n",
    "sorted_termes2 = sorted(TermesNormalisation2)\n",
    "sorted_termes3 = sorted(TermesNormalisation3)\n",
    "sorted_termes4 = sorted(TermesNormalisation4)\n",
    "sorted_termes5 = sorted(TermesNormalisation5)\n",
    "sorted_termes6 = sorted(TermesNormalisation6)\n",
    "# print(sorted_termes1)\n",
    "# print(sorted_termes2)\n",
    "# print(sorted_termes3)\n",
    "# print(sorted_termes4)\n",
    "# print(sorted_termes5)\n",
    "# print(sorted_termes6)\n",
    "\n",
    "\n",
    "sorted_termes1 = [f'{terme}     1' for terme in sorted_termes1]\n",
    "sorted_termes2 = [f'{terme}     2' for terme in sorted_termes2]\n",
    "sorted_termes3 = [f'{terme}     3' for terme in sorted_termes3]\n",
    "sorted_termes4 = [f'{terme}     4' for terme in sorted_termes4]\n",
    "sorted_termes5 = [f'{terme}     5' for terme in sorted_termes5]\n",
    "sorted_termes6 = [f'{terme}     6' for terme in sorted_termes6]\n",
    "\n",
    "\n",
    "global_termes = sorted_termes1 + sorted_termes2 + sorted_termes3 + sorted_termes4 + sorted_termes5 + sorted_termes6\n",
    "sorted_global_termes = sorted(global_termes)\n",
    "# print(sorted_global_termes)\n",
    "\n",
    "tooked = []\n",
    "final_global_terms = []\n",
    "for token in sorted_global_termes:\n",
    "    if token not in tooked:\n",
    "        final_global_terms.append(token)\n",
    "        tooked.append(token)\n",
    "\n",
    "with open(file=\"Index/InverseSplitPorter.txt\", mode='w') as f :\n",
    "    for terme in final_global_terms:\n",
    "        f.write(terme + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query', 'reformulation(qr)', 'set', 'techn', 'us', 'transform', 'user’s', 'origin', 'search', 'query', 'text', 'bet', 'align', 'user’s', 'int', 'improv', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'prom', 'approach', 'due', 'abl', 'exploit', 'knowledg', 'inh', 'larg', 'langu', 'models.', 'tak', 'inspir', 'success', 'ensembl', 'prompt', 'strategies', 'benefit', 'many', 'tasks,', 'investig', 'help', 'improv', 'query', 'reformulation.', 'context,', 'propos', 'ensembl', 'bas', 'prompt', 'technique,', 'genqrensembl', 'lev', 'paraphras', 'zero-shot', 'instruct', 'gen', 'multipl', 'set', 'keyword', 'ultim', 'improv', 'retriev', 'performance.', 'introduc', 'post-retrieval', 'variant,', 'genqrensemblerf', 'incorp', 'pseudo', 'relev', 'feedback.', 'evalu', 'four', 'ir', 'benchmarks,', 'find', 'genqrensembl', 'gen', 'bet', 'reform', 'rel', 'ndcg@10', 'improv', '18%', 'map', 'improv', 'upto', '24%', 'prevy', 'zero-shot', 'state-of-art.', 'msmarco', 'pass', 'rank', 'task,', 'genqrensemblerf', 'show', 'rel', 'gain', '5%', 'mrr', 'us', 'pseudo-relevance', 'feedback,', '9%', 'ndcg@10', 'us', 'relev', 'feedback', 'documents.']\n",
      "['rank', 'docu', 'us', 'larg', 'langu', 'model', '(llms)', 'direct', 'fee', 'query', 'candid', 'docu', 'prompt', 'interest', 'pract', 'problem.', 'however,', 'research', 'found', 'difficult', 'outperform', 'fine-tuned', 'baselin', 'rank', 'benchmark', 'datasets.', 'analys', 'pointw', 'listw', 'rank', 'prompt', 'us', 'ex', 'method', 'argu', 'off-the-shelf', 'llms', 'ful', 'understand', 'challeng', 'rank', 'formulations.', 'paper,', 'propos', 'sign', 'reduc', 'burd', 'llms', 'us', 'new', 'techn', 'cal', 'pairw', 'rank', 'prompt', '(prp).', 'result', 'first', 'lit', 'achiev', 'state-of-the-art', 'rank', 'perform', 'standard', 'benchmark', 'us', 'moderate-sized', 'open-sourced', 'llms.', 'trec-dl', '2019', '2020,', 'prp', 'bas', 'flan-ul2', 'model', '20b', 'paramet', 'perform', 'fav', 'prevy', 'best', 'approach', 'literature,', 'bas', 'blackbox', 'commerc', 'gpt-4', '50x', '(estimated)', 'model', 'size,', 'outperform', 'llm-based', 'solutions,', 'instructgpt', '175b', 'parameters,', '10%', 'rank', 'metrics.', 'us', 'prompt', 'templ', 'sev', 'beir', 'tasks,', 'prp', 'outperform', 'superv', 'baselin', 'outperform', 'blackbox', 'commerc', 'chatgpt', 'solv', '4.2%', 'pointw', 'llm-based', 'solv', '10%', 'av', 'ndcg@10.', 'furthermore,', 'propos', 'sev', 'vary', 'prp', 'improv', 'efficy', 'show', 'poss', 'achiev', 'competit', 'result', 'ev', 'linear', 'complex']\n",
      "['larg', 'langu', 'model', '(llm)', 'manifest', 'unparallel', 'model', 'cap', 'vary', 'tasks,', 'e.g.,', 'multi-step', 'reasoning,', 'input', 'model', 'most', 'limit', 'plain', 'text,', 'could', 'long', 'contain', 'noisy', 'information.', 'long', 'text', 'could', 'tak', 'long', 'tim', 'process,', 'thu', 'may', 'efficy', 'enough', 'recommend', 'system', 'requir', 'immedy', 'response.', 'llm-based', 'recommend', 'models,', 'us', 'item', 'id', 'us', 'fil', 'templ', '(i.e.,', 'discret', 'prompt)', 'allow', 'model', 'understand', 'giv', 'task,', 'model', 'us', 'nee', 'extend', 'fine-tuning', 'bridg', 'user/item', 'id', 'templ', 'word', 'unleash', 'pow', 'llm', 'recommendation.', 'address', 'problems,', 'propos', 'distil', 'discret', 'prompt', 'spec', 'task', 'set', 'continu', 'prompt', 'vect', 'bridg', 'id', 'word', 'reduc', 'inf', 'time.', 'also', 'design', 'train', 'strategy', 'attempt', 'improv', 'efficy', 'train', 'models.', 'expery', 'result', 'three', 'real-world', 'dataset', 'demonst', 'effect', 'prompt', 'distil', '(pod)', 'approach', 'sequ', 'recommend', 'top-n', 'recommend', 'tasks.', 'although', 'train', 'efficy', 'sign', 'improved,', 'improv', 'inf', 'efficy', 'limited.', 'find', 'may', 'inspir', 'research', 'commun', 'improv', 'inf', 'efficy', 'llm-based', 'recommend', 'models.']\n",
      "['query', 'reform', 'well-known', 'problem', 'inform', 'retriev', '(ir)', 'aim', 'enh', 'singl', 'search', 'success', 'complet', 'rat', 'autom', 'mod', \"user's\", 'input', 'query.', 'rec', 'method', 'lev', 'larg', 'langu', 'model', '(llms)', 'improv', 'query', 'reformulation,', 'oft', 'gen', 'limit', 'redund', 'expansions,', 'pot', 'constrain', 'effect', 'capt', 'divers', 'intents.', 'paper,', 'propos', 'gencrf:', 'gen', 'clust', 'reform', 'framework', 'capt', 'divers', 'int', 'adapt', 'bas', 'multipl', 'differentiated,', 'well-generated', 'query', 'retriev', 'phas', 'first', 'time.', 'gencrf', 'lev', 'llms', 'gen', 'vary', 'query', 'init', 'query', 'us', 'custom', 'prompts,', 'clust', 'group', 'distinct', 'repres', 'divers', 'intents.', 'furthermore,', 'framework', 'expl', 'combin', 'divers', 'int', 'query', 'innov', 'weight', 'aggreg', 'strategies', 'optim', 'retriev', 'perform', 'cruc', 'integr', 'novel', 'query', 'evalu', 'reward', 'model', '(qerm)', 'refin', 'process', 'feedback', 'loops.', 'empir', 'expery', 'beir', 'benchmark', 'demonst', 'gencrf', 'achiev', 'state-of-the-art', 'performance,', 'surpass', 'prevy', 'query', 'reform', 'sota', '12%', 'ndcg@10.', 'techn', 'adapt', 'vary', 'llms,', 'sign', 'boost', 'retriev', 'perform', 'adv', 'field', 'inform', 'retrieval.']\n",
      "['sess', 'search', 'involv', 'sery', 'interact', 'query', 'act', 'fulfil', \"user's\", 'complex', 'inform', 'need.', 'cur', 'strategies', 'typ', 'priorit', 'sequ', 'model', 'deep', 'sem', 'understanding,', 'overlook', 'graph', 'structure', 'interactions.', 'approach', 'foc', 'capt', 'structural', 'information,', 'us', 'gen', 'repres', 'documents,', 'neglect', 'word-level', 'sem', 'modeling.', 'paper,', 'propos', 'symbol', 'graph', 'rank', '(sgr),', 'aim', 'tak', 'adv', 'text-based', 'graph-based', 'approach', 'lev', 'pow', 'rec', 'larg', 'langu', 'model', '(llms).', 'concretely,', 'first', 'introduc', 'set', 'symbol', 'gramm', 'rul', 'convert', 'sess', 'graph', 'text.', 'allow', 'integr', 'sess', 'history,', 'interact', 'process,', 'task', 'instruct', 'seamless', 'input', 'llm.', 'moreover,', 'giv', 'nat', 'discrep', 'llms', 'pre-trained', 'text', 'corpora,', 'symbol', 'langu', 'produc', 'us', 'graph-to-text', 'grammar,', 'object', 'enh', \"llms'\", 'abl', 'capt', 'graph', 'structures', 'within', 'text', 'format.', 'achiev', 'this,', 'introduc', 'set', 'self-supervised', 'symbol', 'learn', 'task', 'includ', 'link', 'prediction,', 'nod', 'cont', 'generation,', 'gen', 'contrast', 'learning,', 'en', 'llms', 'capt', 'topolog', 'inform', 'coarse-grained', 'fine-grained.', 'expery', 'result', 'comprehend', 'analys', 'two', 'benchmark', 'datasets,', 'aol', 'tiangong-st,', 'confirm', 'supery', 'approach.', 'paradigm', 'also', 'off', 'novel', 'effect', 'methodolog', 'bridg', 'gap', 'tradit', 'search', 'strategies', 'modern', 'llms.']\n",
      "['describ', 'item', 'play', 'pivot', 'rol', 'provid', 'cont', 'inform', 'sum', 'capt', 'pot', 'view', 'ess', 'recommend', 'systems.', 'traditionally,', 'describ', 'obtain', 'man', 'web', 'scraping', 'techniques,', 'time-consuming', 'suscept', 'dat', 'inconsistencies.', 'rec', 'years,', 'larg', 'langu', 'model', '(llms),', 'gpt-3.5,', 'op', 'sourc', 'llms', 'lik', 'alpac', 'emerg', 'pow', 'tool', 'nat', 'langu', 'process', 'tasks.', 'paper,', 'expl', 'us', 'llms', 'gen', 'detail', 'describ', 'items.', 'conduc', 'study,', 'us', 'moviel', '1m', 'dataset', 'compr', 'movy', 'titl', 'goodread', 'dataset', 'consist', 'nam', 'book', 'subsequently,', 'open-sourced', 'llm,', 'alpaca,', 'prompt', 'few-shot', 'prompt', 'dataset', 'gen', 'detail', 'movy', 'describ', 'consid', 'multipl', 'feat', 'lik', 'nam', 'cast', 'direct', 'ml', 'dataset', 'nam', 'auth', 'publ', 'goodread', 'dataset.', 'gen', 'describ', 'comp', 'scraped', 'describ', 'us', 'combin', 'top', 'hits,', 'mrr,', 'ndcg', 'evalu', 'metrics.', 'result', 'demonst', 'llm-based', 'movy', 'describ', 'gen', 'exhibit', 'sign', 'promise,', 'result', 'comp', 'on', 'obtain', 'web-scraped', 'descriptions.']\n"
     ]
    }
   ],
   "source": [
    "TermesNormalisation1 = [Lancaster.stem(terme) for terme in TermesSansMotsVides1]\n",
    "TermesNormalisation2 = [Lancaster.stem(terme) for terme in TermesSansMotsVides2]\n",
    "TermesNormalisation3 = [Lancaster.stem(terme) for terme in TermesSansMotsVides3]\n",
    "TermesNormalisation4 = [Lancaster.stem(terme) for terme in TermesSansMotsVides4]\n",
    "TermesNormalisation5 = [Lancaster.stem(terme) for terme in TermesSansMotsVides5]\n",
    "TermesNormalisation6 = [Lancaster.stem(terme) for terme in TermesSansMotsVides6]\n",
    "\n",
    "print(TermesNormalisation1)\n",
    "print(TermesNormalisation2)\n",
    "print(TermesNormalisation3)\n",
    "print(TermesNormalisation4)\n",
    "print(TermesNormalisation5)\n",
    "print(TermesNormalisation6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"Index/DescripteursSplitLancaster.txt\", mode='w') as f :\n",
    "    for terme in TermesNormalisation1:\n",
    "        f.write('1.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation2:\n",
    "        f.write('2.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation3:\n",
    "        f.write('3.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation4:\n",
    "        f.write('4.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation5:\n",
    "        f.write('5.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation6:\n",
    "        f.write('6.' + terme+'\\n')\n",
    "\n",
    "# with open(file=\"Index/InverseSplitLancaster.txt\", mode='w') as f :\n",
    "#     for terme in TermesNormalisation1:\n",
    "#         f.write(terme+ '    1' + '\\n')\n",
    "#     for terme in TermesNormalisation2:\n",
    "#         f.write(terme + '   2' +'\\n')\n",
    "#     for terme in TermesNormalisation3:\n",
    "#         f.write(terme + '   3' +'\\n')\n",
    "#     for terme in TermesNormalisation4:\n",
    "#         f.write(terme+ '    4' +'\\n')\n",
    "#     for terme in TermesNormalisation5:\n",
    "#         f.write(terme+ '    5' + '\\n')\n",
    "#     for terme in TermesNormalisation6:\n",
    "#         f.write(terme + '   6' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_termes1 = sorted(TermesNormalisation1)\n",
    "sorted_termes2 = sorted(TermesNormalisation2)\n",
    "sorted_termes3 = sorted(TermesNormalisation3)\n",
    "sorted_termes4 = sorted(TermesNormalisation4)\n",
    "sorted_termes5 = sorted(TermesNormalisation5)\n",
    "sorted_termes6 = sorted(TermesNormalisation6)\n",
    "# print(sorted_termes1)\n",
    "# print(sorted_termes2)\n",
    "# print(sorted_termes3)\n",
    "# print(sorted_termes4)\n",
    "# print(sorted_termes5)\n",
    "# print(sorted_termes6)\n",
    "\n",
    "\n",
    "\n",
    "sorted_termes1 = [f'{terme}     1' for terme in sorted_termes1]\n",
    "sorted_termes2 = [f'{terme}     2' for terme in sorted_termes2]\n",
    "sorted_termes3 = [f'{terme}     3' for terme in sorted_termes3]\n",
    "sorted_termes4 = [f'{terme}     4' for terme in sorted_termes4]\n",
    "sorted_termes5 = [f'{terme}     5' for terme in sorted_termes5]\n",
    "sorted_termes6 = [f'{terme}     6' for terme in sorted_termes6]\n",
    "\n",
    "\n",
    "\n",
    "global_termes = sorted_termes1 + sorted_termes2 + sorted_termes3 + sorted_termes4 + sorted_termes5 + sorted_termes6\n",
    "sorted_global_termes = sorted(global_termes)\n",
    "# print(sorted_global_termes)\n",
    "\n",
    "tooked = []\n",
    "final_global_terms = []\n",
    "for token in sorted_global_termes:\n",
    "    if token not in tooked:\n",
    "        final_global_terms.append(token)\n",
    "        tooked.append(token)\n",
    "\n",
    "\n",
    "\n",
    "with open(file=\"Index/InverseSplitLancaster.txt\", mode='w') as f :\n",
    "    for terme in final_global_terms:\n",
    "        f.write(terme + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+|\\.{3}')  \n",
    "\n",
    "termes1 = txt1.lower().split()\n",
    "print(termes1)\n",
    "termes2 = txt2.lower().split()\n",
    "print(termes2)\n",
    "termes3 = txt3.lower().split()\n",
    "print(termes3)\n",
    "termes4 = txt4.lower().split()\n",
    "print(termes4)\n",
    "termes5 = txt5.lower().split()\n",
    "print(termes5)\n",
    "termes6 = txt6.lower().split()\n",
    "print(termes6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"Index/DescripteursTokenPorter.txt\", mode='w') as f :\n",
    "    for terme in TermesNormalisation1:\n",
    "        f.write('1.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation2:\n",
    "        f.write('2.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation3:\n",
    "        f.write('3.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation4:\n",
    "        f.write('4.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation5:\n",
    "        f.write('5.' + terme+'\\n')\n",
    "    for terme in TermesNormalisation6:\n",
    "        f.write('6.' + terme+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
